{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-To Guide into Feature Engineering  \n",
    "\n",
    "## Introduction\n",
    "\n",
    "If you haven't yet see the [overview posting] for this series, please take a minute to read that first...  Are you back?  Great.  Let's dive in.  \n",
    "\n",
    "This post is going to delve into the mechanics of _feature engineering_ for the sorts of time series data that you may use as part of a stock price prediction modeling system.  I'll cover the basic concept, then offer some useful python code \"recipes\" for transforming your raw source data into features which can be fed directly into a ML algorithm or ML pipeline.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "I believe (and I don't think I'm alone) that featue engineering is the most under-appreciated part of the art of machine learning.  It's certainly the most time consuming and tedious, but it's creative and \"fun\" (for those who like getting their hands dirty with data, anyway...).  \n",
    "\n",
    "Feature engineering is also one of the key areas where those with domain expertise can shine.  Those whose expertise in investing is greater than their skill in machine learning will find that feature engineering will allow them to express that expertise.  \n",
    "\n",
    "It is particularly important to making stock predictions.  All too often, I come across an online tutorial on forecasting stock prices which simply feed in daily returns (or worse, daily prices!) into a mind-blowingly complex algorithm and conclude that machine learning does not work for price prediction. \n",
    "\n",
    "Feature engineering is a term of art for data science and machine learning which refers to pre-processing and transforming raw data to distill it into a form which is more easily used by machine learning algorithms.  Much like chemical processing can extract pure gold from trace elements within ore, feature engineering can extract value from very noisy data.  \n",
    "\n",
    "Anyone who has dabbled with any systems-based trading or charting already has experience with simple forms of feature engineering, whether or not they realized it.  For instance:\n",
    "* Converting a series of asset prices into percent change values is a simple form of feature engineering\n",
    "* Charting prices vs. a moving average is an implicit form of feature engineering\n",
    "* Any technical indicator (RSI, MACD, etc...) are also forms of feature engineering\n",
    "\n",
    "The process takes in one or more columns of \"raw\" input data (e.g., OHLC price data, 10-Q financials, social media sentiment, etc...) and converts it into _many_ columns of engineered features.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words of Warning\n",
    "\n",
    "Feature engineering is fundamentally a creative process.  As such, I believe there should be a minimum of rules or limits placed on it.  However, I do believe there are a few guidelines to be followed:  \n",
    "\n",
    "* __No peeking:__ Peeking (into the future) is the original sin of feature engineering (and prediction modeling in general).  It refers to using information about the future (or information which would not yet be known by us...) to engineer a piece of data.  This can be obvious, like using next_12_months_returns.  However, it's most often quite subtle, like using the mean or standard deviation across the full time period to normalize data points (which implicitly leaks future information into our features.  The test is whether you would be able to get __the exact same value__ if you were calculating the data point at that point in time rather than today.  \n",
    "\n",
    "* __Only the knowable:__ A corrolary to the above, you also need to be honest about what you would have known at the time, not just what had happened at the time.  For instance, short borrowing data is reported by exchanges with a considerable time lag.  You would want to stamp the feature with the date on which you _would have known_ it.  \n",
    "\n",
    "* __Complete the table:__ Many machine learning algorithms expect that every input feature will have a value (of a certain type) for each observation.  If you envision a spreadsheet where each feature is a column and each observation is a row, there should be a value in each cell of the table.  Quite often, some features in the table will naturally update themselves more frequently than others.  Price data updates almost continuously, while short inventory, analyst estimates, or EBITDA tend to update every few weeks or months.  In these cases, we'll use a scheme like last observation carried forward (LOCF) to always have a value for each feature in the naturally lower frequency columns.  Of course, we will be careful to avoid inadvertent peeking!\n",
    "\n",
    "* __Avoid false ordinality:__ Finally, it's extremely important to represent features in a way that captures ordinality only if it has meaning.  For instance, it's usually a bad idea to represent \"day of the week\" as an integer 1 to 7 since this implicitly tells the model to treat Friday as very similar to Thursday, but \"a little more\".  It would also say that Sunday and Monday are totally different (if Sunday =7 and Monday =1). We could miss all manner of interesting patterns in the data.  \n",
    "\n",
    "## Getting Started\n",
    "Let's dive in.  I will begin by extracting some toy data into a dataframe using free data from [quandl](https://www.quandl.com/): \n",
    "\n",
    "First, we'll make a utility function which downloads one or more symbols from quandl and returns the adjusted OHLC data (I generally find adjusted data to be best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like # remove once updated pandas-datareader issue is fixed\n",
    "# https://github.com/pydata/pandas-datareader/issues/534\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "def get_symbols(symbols,data_source, begin_date=None,end_date=None):\n",
    "    out = pd.DataFrame()\n",
    "    for symbol in symbols:\n",
    "        df = web.DataReader(symbol, data_source,begin_date, end_date)[['AdjOpen','AdjHigh','AdjLow','AdjClose','AdjVolume']].reset_index()\n",
    "        df.columns = ['date','open','high','low','close','volume'] #my convention: always lowercase\n",
    "        df['symbol'] = symbol # add a new column which contains the symbol so we can keep multiple symbols in the same dataframe\n",
    "        df = df.set_index(['date','symbol'])\n",
    "        out = pd.concat([out,df],axis=0) #stacks on top of previously collected data\n",
    "    return out.sort_index()\n",
    "        \n",
    "prices = get_symbols(['AAPL','CSCO'],data_source='quandl',begin_date='2015-01-01',end_date='2017-01-01')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO BE COVERED\n",
    "BASICS\n",
    "* workflow from data to feature frame\n",
    "* \n",
    "\n",
    "TECHNIQUES\n",
    "* groupby\n",
    "* rolling\n",
    "* lambda\n",
    "\n",
    "TRANSFORMS\n",
    "* chg, pct chg\n",
    "* MA/EMA, diffMA\n",
    "* binning\n",
    "* percentile\n",
    "* rank\n",
    "* one-hot\n",
    "* Z-scores\n",
    "* sign, sign if greater than...\n",
    "* streak\n",
    "* techincal indicators #https://github.com/bukosabino/ta\n",
    "* calendar\n",
    "\n",
    "\n",
    "DATA CLEANING\n",
    "* to_datetime\n",
    "* to_numeric\n",
    "* missing fillna (ffill, mean w/peeking)\n",
    "* \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>volume_change_ratio</th>\n",
       "      <th>momentum_5_day</th>\n",
       "      <th>intraday_chg</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-23</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.453747</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.291298</td>\n",
       "      <td>-0.001961</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-27</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.284036</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.546260</td>\n",
       "      <td>-0.002276</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-28</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.142595</td>\n",
       "      <td>-0.001625</td>\n",
       "      <td>-0.006467</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.151900</td>\n",
       "      <td>-0.004581</td>\n",
       "      <td>-0.009121</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-29</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.280609</td>\n",
       "      <td>-0.002819</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.085396</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-30</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.033726</td>\n",
       "      <td>-0.004042</td>\n",
       "      <td>-0.007115</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.836194</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   volume_change_ratio  momentum_5_day  intraday_chg  \\\n",
       "date       symbol                                                      \n",
       "2016-12-23 AAPL              -0.453747        0.004743      0.008046   \n",
       "           CSCO              -0.291298       -0.001961     -0.000327   \n",
       "2016-12-27 AAPL               0.284036        0.005316      0.006351   \n",
       "           CSCO               0.546260       -0.002276      0.001305   \n",
       "2016-12-28 AAPL               0.142595       -0.001625     -0.006467   \n",
       "           CSCO              -0.151900       -0.004581     -0.009121   \n",
       "2016-12-29 AAPL              -0.280609       -0.002819      0.002404   \n",
       "           CSCO              -0.085396        0.001315      0.002963   \n",
       "2016-12-30 AAPL               1.033726       -0.004042     -0.007115   \n",
       "           CSCO               0.836194       -0.007879     -0.011126   \n",
       "\n",
       "                   day_of_week  day_of_month  \n",
       "date       symbol                             \n",
       "2016-12-23 AAPL              4            23  \n",
       "           CSCO              4            23  \n",
       "2016-12-27 AAPL              1            27  \n",
       "           CSCO              1            27  \n",
       "2016-12-28 AAPL              2            28  \n",
       "           CSCO              2            28  \n",
       "2016-12-29 AAPL              3            29  \n",
       "           CSCO              3            29  \n",
       "2016-12-30 AAPL              4            30  \n",
       "           CSCO              4            30  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(index=prices.index)\n",
    "features['volume_change_ratio'] = prices.groupby(level='symbol').volume.diff(1) / prices.groupby(level='symbol').shift(1).volume\n",
    "features['momentum_5_day'] = prices.groupby(level='symbol').close.pct_change(5) \n",
    "features['intraday_chg'] = (prices.groupby(level='symbol').close.shift(0) - prices.groupby(level='symbol').open.shift(0))/prices.groupby(level='symbol').open.shift(0)\n",
    "features['day_of_week'] = features.index.get_level_values('date').weekday\n",
    "features['day_of_month'] = features.index.get_level_values('date').day\n",
    "features.dropna(inplace=True)\n",
    "features.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the syntax or logic of the features isn't immediately clear, I'll cover that in more depth in [the next post].  For now, just note that we've created five features for both symbols using only data that would be available _as of the end of day T_.  \n",
    "\n",
    "Also note that I've dropped any rows which contain any nulls for simplicity, since scikit-learn can't handle those out of the box.  \n",
    "\n",
    "Next, we'll create outcomes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open_1</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-21</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.006065</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.002827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.001313</td>\n",
       "      <td>-0.001313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-22</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.006019</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.002293</td>\n",
       "      <td>0.007942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-23</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.004889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-27</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-28</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.002655</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.001644</td>\n",
       "      <td>-0.001313</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-29</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.003283</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-30</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     open_1   close_1   close_5\n",
       "date       symbol                              \n",
       "2016-12-20 CSCO    0.004254  0.004602  0.004602\n",
       "2016-12-21 AAPL   -0.006065  0.006621  0.002827\n",
       "           CSCO   -0.000657 -0.001313 -0.001313\n",
       "2016-12-22 AAPL   -0.006019 -0.001974  0.004058\n",
       "           CSCO    0.002626 -0.002293  0.007942\n",
       "2016-12-23 AAPL    0.000000 -0.006311       NaN\n",
       "           CSCO    0.003603 -0.004889       NaN\n",
       "2016-12-27 AAPL    0.002217  0.004282       NaN\n",
       "           CSCO    0.000652  0.008547       NaN\n",
       "2016-12-28 AAPL   -0.002655  0.000257       NaN\n",
       "           CSCO   -0.001644 -0.001313       NaN\n",
       "2016-12-29 AAPL   -0.000685  0.007857       NaN\n",
       "           CSCO    0.003283  0.007942       NaN\n",
       "2016-12-30 AAPL         NaN       NaN       NaN\n",
       "           CSCO         NaN       NaN       NaN"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = pd.DataFrame(index=prices.index)\n",
    "# next day's opening change\n",
    "outcomes['open_1'] = prices.groupby(level='symbol').open.shift(-1)/prices.groupby(level='symbol').close.shift(0)-1\n",
    "# next day's closing change\n",
    "outcomes['close_1'] = prices.groupby(level='symbol').close.pct_change(-1)\n",
    "outcomes['close_5'] = prices.groupby(level='symbol').close.pct_change(-5)\n",
    "\n",
    "(outcomes.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shifted periods are negative, which in pandas convention looks _ahead_ in time.  This means that at the ending of our time period we will have nulls - and more nulls in the outcome colums that need to look further into the future.  We don't dropna() here since we may want to use `open_1` and there's no reason to throw away data from that column just because _a different_ outcome didn't have data.  But I digress.\n",
    "\n",
    "Now, to put it together, we'll train a simple linear model in `scikit-learn`, using all features to predict `close_1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(996,)\n",
      "(996, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# first, create y (a series) and X (a dataframe), with only rows where \n",
    "# a valid value exists for both y and X\n",
    "y = outcomes.close_1\n",
    "X = features\n",
    "Xy = X.join(y).dropna()\n",
    "y = Xy[y.name]\n",
    "X = Xy[X.columns]\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all of these slightly tedious steps have left us with properly sized, identically indexed data objects.  At this point, the modeling is dead simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RSQ: 0.01598347165537528\n",
      "Coefficients: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intraday_chg           0.150482\n",
       "volume_change_ratio    0.000976\n",
       "day_of_month           0.000036\n",
       "day_of_week           -0.000427\n",
       "momentum_5_day        -0.005543\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "print(\"Model RSQ: \"+ str(model.score(X,y)))\n",
    "\n",
    "print(\"Coefficients: \")\n",
    "pd.Series(model.coef_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this model isn't very useful but illustrates the point. If we wanted to instead create a random forest to predict tomorrow's open, it'd be mostly copy-paste: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(996,)\n",
      "(996, 5)\n",
      "Model Score: 0.7941872364575131\n",
      "Feature Importance: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "momentum_5_day         0.269462\n",
       "intraday_chg           0.266634\n",
       "volume_change_ratio    0.257447\n",
       "day_of_month           0.129595\n",
       "day_of_week            0.076862\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "y = outcomes.open_1\n",
    "X = features\n",
    "Xy = X.join(y).dropna()\n",
    "y = Xy[y.name]\n",
    "X = Xy[X.columns]\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "\n",
    "model = RandomForestRegressor(max_features=3)\n",
    "model.fit(X,y)\n",
    "print(\"Model Score: \"+ str(model.score(X,y)))\n",
    "\n",
    "print(\"Feature Importance: \")\n",
    "pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields a vastly improved RSQ but note that it is almost certainly ridiculously overfitted, as random forests are prone to do.  \n",
    "\n",
    "We'll cover ways to systematically avoid allowing the model to overfit in future posts, but that requires going a bit further down the rabbit hole.  \n",
    "\n",
    "One side point: in this example (and often, in real life) we've mixed together all observations from AAPL and CSCO into one dataset.  We could have alternatively trained two different models for the two symbols, which may have achieved better fit, but almost certainly at the cost of worse generalization out of sample.  The bias-variance trade-off in action!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction\n",
    "Once the model is trained, it becomes a one-liner to make predictions from a set of feature values.  In this case, we'll simply feed the same X values used to train the model, but in live usage, of course, we'd want to apply the trained model to _new_ X values.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        symbol\n",
       "2016-12-22  AAPL     -0.001943\n",
       "            CSCO      0.003121\n",
       "2016-12-23  AAPL     -0.000231\n",
       "            CSCO      0.002466\n",
       "2016-12-27  AAPL      0.002638\n",
       "            CSCO      0.001447\n",
       "2016-12-28  AAPL     -0.002669\n",
       "            CSCO     -0.000287\n",
       "2016-12-29  AAPL      0.000690\n",
       "            CSCO      0.002967\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.predict(X),index=X.index).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me pause here to emphasize the most critical point to understand about this framework.  Read this twice!\n",
    "\n",
    "The date of a feature row represents the day when a value would be known _after that day's trading_, using the feature value date as T=0.  The date of an outcome row represents what will happen in the n days _following_ that date.\n",
    "\n",
    "** Predictions are indexed to the date of the _evening_ when the model could have been run**, _not_ on the day when it could have been traded. \n",
    "\n",
    "In other words, on 2016-12-23, the prediction value represents what the model believes will happen _after_ 12/23.  In practical usage, we can't start using the trading signal until T+1 (since we can't get predictions until after markets are closed on T+0).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary\n",
    "This post presented the concept of organizing data into a `features` dataframe and `outcome` dataframe, and then showed how simple it is to join these two dataframes together to train a model.  \n",
    "\n",
    "True, the convention may take a few examples to get used to.  However, after trial and error, I've found this to be the most error-resistant, flexible, and high-performance way to go.\n",
    "\n",
    "In the [next post], I will share some methods of feature engineering and feature selection.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
