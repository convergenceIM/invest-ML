{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Generalized Framework for Machine Learning applied to Stock Prediction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Use of machine learning in the quantitative investment field is, by all indications, skyrocketing.  The proliferation of easily accessible data - both traditional and alternative - along with some very approachable frameworks for machine learning models - is encouraging many to explore the arena.\n",
    "\n",
    "However, usage of machine learning in stock market prediction requires much more than a good grasp of the concepts and techniques for supervised machine learning.  As I describe further in [this post], stock prediction is a challenging domain which requires some special techniques to overcome issues like non-stationarity, collinearity, and low signal-to-noise.  \n",
    "\n",
    "In this and following posts, I'll present the design of an end-to-end system for developing, testing, and applying machine learning models in a way which addresses each of these problems in a very practical way.  These postings _will not_ offer any \"secret sauce\" or strategies which I use in live trading, but will offer a more valuable and more generalized set of techniques which will allow you to create your own strategies in a *robust manner*.  \n",
    "\n",
    "Within other posts in this series, I plan to cover:\n",
    "* Feature engineering / target engineering\n",
    "* Feature selection\n",
    "* Evaluating and comparing model performance (hint: not backtesting)\n",
    "* Walk-forward out-of-sample training/testing\n",
    "* Building ensemble models to combine many distinct, weak signals\n",
    "* Using Pandas, scikit-learn, and pandas plus scikit-learn\n",
    "* Techniques for improving model predictive power\n",
    "* Techniques for improving model robustness out-of-sample\n",
    "... and more \n",
    "\n",
    "In this first post - before covering these specifics - I will present a high-level framework which sets the stage for modeling.  For this, I will assume readers have a good working knowledge of [pandas DataFrames] and of basic supervised machine learning concepts.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Data Structures\n",
    "\n",
    "As will become clear as I build out examples, it's crucial that our framework uses a smartly designed set of conventions for how to organize and use data.  My system makes heavy use of three distinct types of data:\n",
    "\n",
    "* __features:__ This is a dataframe which contains all _features_ or values which we will allow models to use in the course of learning relationships - and later making predictions.  All features must be values which would have been known __at the point in time when the model needed to make predictions__.  In other words, `next_12_months_returns` would be a bad feature since it would not become known at the time needed.  The `features` dataframe has a multi-index of date/symbol and column names unique to each feature.  More on this later.   \n",
    "* __outcomes:__ This is a dataframe of all possible __future__ outcomes which we may be interested in predicting, magically shifted back in time to T-zero.  For instance, we may want to predict the total_return for a symbol over the year following T=0 (the time of prediction).  We would look ahead into the future, calculate what ultimately did happen to this metric, and log it onto time T=0.  I'll explain why in a minute.  Just like `features`, this dataframe has rows indexed by date/symbol and columns named with a convention which describes the feature.  \n",
    "* __master:__ The final data structure type is the `master` dataframe.  This contains any _static_ information about each symbol in the universe, such as the SIC code, the number of shares outstanding, beta factors, etc...  In practice, things in the master may change over time (SIC codes and shares out can both change...) but I've found it sufficient for my purposes to take the current static values for the current point in time.  This dataframe uses row index of symbol only.  You could, of course, add a date/symbol index if you wanted to reflect changing values over time.  \n",
    "\n",
    "## Why this data structure scheme?\n",
    "It may seem odd to split the features and outcomes into distinct dataframes, and odd to create a dataframe of several different possible \"outcomes\".  It may seem odd to record on t=0 what will happen in the _next_ year or whatever.  There are two reasons for this:\n",
    "1. This makes it trivial to extract the X's and y's when training models.  We only ever use one or more columns of `features` in the X and one column of `outcomes` in y.  \n",
    "2. This makes it trivial to toggle between various time horizons - just change the column of `outcomes` used for y.\n",
    "3. This helps us guard against inadvertent \"peeking\" at the future by being very careful not to let any future information leak into the `features` frame - and then only using subsets of that frame for X.  \n",
    "4. This allows us to use the incredibly efficient pandas `join`, `merge`, and `concat` methods to quickly align data for purposes of training models.  Trust me.  \n",
    "\n",
    "This will save you untold grey hairs and hours of debugging.  \n",
    "\n",
    "Before going further, let's create simple toy examples of each dataframe using free data from [quandl](https://www.quandl.com/): \n",
    "\n",
    "First, we'll make a utility function which downloads one or more symbols from quandl and returns the adjusted OHLC data (I generally find adjusted data to be best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "\n",
    "def get_symbols(symbols,data_source, begin_date=None,end_date=None):\n",
    "    out = pd.DataFrame()\n",
    "    for symbol in symbols:\n",
    "        df = web.DataReader(symbol, data_source,begin_date, end_date)[['AdjOpen','AdjHigh','AdjLow','AdjClose','AdjVolume']].reset_index()\n",
    "        df.columns = ['date','open','high','low','close','volume'] #my convention: always lowercase\n",
    "        df['symbol'] = symbol # add a new column which contains the symbol so we can keep multiple symbols in the same dataframe\n",
    "        df = df.set_index(['date','symbol'])\n",
    "        out = pd.concat([out,df],axis=0) #stacks on top of previously collected data\n",
    "    return out.sort_index()\n",
    "        \n",
    "prices = get_symbols(['AAPL','CSCO'],data_source='quandl',begin_date='2015-01-01',end_date='2017-01-01')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create some toy features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>volume_change_ratio</th>\n",
       "      <th>momentum_5_day</th>\n",
       "      <th>intraday_chg</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-23</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.453747</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.291298</td>\n",
       "      <td>-0.001961</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-27</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.284036</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.546260</td>\n",
       "      <td>-0.002276</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-28</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.142595</td>\n",
       "      <td>-0.001625</td>\n",
       "      <td>-0.006467</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.151900</td>\n",
       "      <td>-0.004581</td>\n",
       "      <td>-0.009121</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-29</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.280609</td>\n",
       "      <td>-0.002819</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.085396</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-30</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.033726</td>\n",
       "      <td>-0.004042</td>\n",
       "      <td>-0.007115</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.836194</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   volume_change_ratio  momentum_5_day  intraday_chg  \\\n",
       "date       symbol                                                      \n",
       "2016-12-23 AAPL              -0.453747        0.004743      0.008046   \n",
       "           CSCO              -0.291298       -0.001961     -0.000327   \n",
       "2016-12-27 AAPL               0.284036        0.005316      0.006351   \n",
       "           CSCO               0.546260       -0.002276      0.001305   \n",
       "2016-12-28 AAPL               0.142595       -0.001625     -0.006467   \n",
       "           CSCO              -0.151900       -0.004581     -0.009121   \n",
       "2016-12-29 AAPL              -0.280609       -0.002819      0.002404   \n",
       "           CSCO              -0.085396        0.001315      0.002963   \n",
       "2016-12-30 AAPL               1.033726       -0.004042     -0.007115   \n",
       "           CSCO               0.836194       -0.007879     -0.011126   \n",
       "\n",
       "                   day_of_week  day_of_month  \n",
       "date       symbol                             \n",
       "2016-12-23 AAPL              4            23  \n",
       "           CSCO              4            23  \n",
       "2016-12-27 AAPL              1            27  \n",
       "           CSCO              1            27  \n",
       "2016-12-28 AAPL              2            28  \n",
       "           CSCO              2            28  \n",
       "2016-12-29 AAPL              3            29  \n",
       "           CSCO              3            29  \n",
       "2016-12-30 AAPL              4            30  \n",
       "           CSCO              4            30  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(index=prices.index)\n",
    "features['volume_change_ratio'] = prices.groupby(level='symbol').volume.diff(1) / prices.groupby(level='symbol').shift(1).volume\n",
    "features['momentum_5_day'] = prices.groupby(level='symbol').close.pct_change(5) \n",
    "features['intraday_chg'] = (prices.groupby(level='symbol').close.shift(0) - prices.groupby(level='symbol').open.shift(0))/prices.groupby(level='symbol').open.shift(0)\n",
    "features['day_of_week'] = features.index.get_level_values('date').weekday\n",
    "features['day_of_month'] = features.index.get_level_values('date').day\n",
    "features.dropna(inplace=True)\n",
    "features.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the syntax or logic of the features isn't immediately clear, I'll cover that in more depth in [the next post].  For now, just note that we've created five features for both symbols using only data that would be available _as of the end of day T_.  \n",
    "\n",
    "Also note that I've dropped any rows which contain any nulls for simplicity, since scikit-learn can't handle those out of the box.  \n",
    "\n",
    "Next, we'll create outcomes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open_1</th>\n",
       "      <th>close_1</th>\n",
       "      <th>close_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-21</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.006065</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.002827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.001313</td>\n",
       "      <td>-0.001313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-22</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.006019</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.002293</td>\n",
       "      <td>0.007942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-23</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.004889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-27</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-28</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.002655</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>-0.001644</td>\n",
       "      <td>-0.001313</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-29</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>0.003283</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016-12-30</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSCO</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     open_1   close_1   close_5\n",
       "date       symbol                              \n",
       "2016-12-20 CSCO    0.004254  0.004602  0.004602\n",
       "2016-12-21 AAPL   -0.006065  0.006621  0.002827\n",
       "           CSCO   -0.000657 -0.001313 -0.001313\n",
       "2016-12-22 AAPL   -0.006019 -0.001974  0.004058\n",
       "           CSCO    0.002626 -0.002293  0.007942\n",
       "2016-12-23 AAPL    0.000000 -0.006311       NaN\n",
       "           CSCO    0.003603 -0.004889       NaN\n",
       "2016-12-27 AAPL    0.002217  0.004282       NaN\n",
       "           CSCO    0.000652  0.008547       NaN\n",
       "2016-12-28 AAPL   -0.002655  0.000257       NaN\n",
       "           CSCO   -0.001644 -0.001313       NaN\n",
       "2016-12-29 AAPL   -0.000685  0.007857       NaN\n",
       "           CSCO    0.003283  0.007942       NaN\n",
       "2016-12-30 AAPL         NaN       NaN       NaN\n",
       "           CSCO         NaN       NaN       NaN"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = pd.DataFrame(index=prices.index)\n",
    "# next day's opening change\n",
    "outcomes['open_1'] = prices.groupby(level='symbol').open.shift(-1)/prices.groupby(level='symbol').close.shift(0)-1\n",
    "# next day's closing change\n",
    "outcomes['close_1'] = prices.groupby(level='symbol').close.pct_change(-1)\n",
    "outcomes['close_5'] = prices.groupby(level='symbol').close.pct_change(-5)\n",
    "\n",
    "(outcomes.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shifted periods are negative, which in pandas convention looks _ahead_ in time.  This means that at the ending of our time period we will have nulls - and more nulls in the outcome colums that need to look further into the future.  We don't dropna() here since we may want to use `open_1` and there's no reason to throw away data from that column just because _a different_ outcome didn't have data.  But I digress.\n",
    "\n",
    "Now, to put it together, we'll train a simple linear model in `scikit-learn`, using all features to predict `close_1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(996,)\n",
      "(996, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# first, create y (a series) and X (a dataframe), with only rows where \n",
    "# a valid value exists for both y and X\n",
    "y = outcomes.close_1\n",
    "X = features\n",
    "Xy = X.join(y).dropna()\n",
    "y = Xy[y.name]\n",
    "X = Xy[X.columns]\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all of these slightly tedious steps have left us with properly sized, identically indexed data objects.  At this point, the modeling is dead simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RSQ: 0.01598347165537528\n",
      "Coefficients: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intraday_chg           0.150482\n",
       "volume_change_ratio    0.000976\n",
       "day_of_month           0.000036\n",
       "day_of_week           -0.000427\n",
       "momentum_5_day        -0.005543\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "print(\"Model RSQ: \"+ str(model.score(X,y)))\n",
    "\n",
    "print(\"Coefficients: \")\n",
    "pd.Series(model.coef_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this model isn't very useful but illustrates the point. If we wanted to instead create a random forest to predict tomorrow's open, it'd be mostly copy-paste: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(996,)\n",
      "(996, 5)\n",
      "Model Score: 0.7941872364575131\n",
      "Feature Importance: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "momentum_5_day         0.269462\n",
       "intraday_chg           0.266634\n",
       "volume_change_ratio    0.257447\n",
       "day_of_month           0.129595\n",
       "day_of_week            0.076862\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "y = outcomes.open_1\n",
    "X = features\n",
    "Xy = X.join(y).dropna()\n",
    "y = Xy[y.name]\n",
    "X = Xy[X.columns]\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "\n",
    "model = RandomForestRegressor(max_features=3)\n",
    "model.fit(X,y)\n",
    "print(\"Model Score: \"+ str(model.score(X,y)))\n",
    "\n",
    "print(\"Feature Importance: \")\n",
    "pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields a vastly improved RSQ but note that it is almost certainly ridiculously overfitted, as random forests are prone to do.  \n",
    "\n",
    "We'll cover ways to systematically avoid allowing the model to overfit in future posts, but that requires going a bit further down the rabbit hole.  \n",
    "\n",
    "One side point: in this example (and often, in real life) we've mixed together all observations from AAPL and CSCO into one dataset.  We could have alternatively trained two different models for the two symbols, which may have achieved better fit, but almost certainly at the cost of worse generalization out of sample.  The bias-variance trade-off in action!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction\n",
    "Once the model is trained, it becomes a one-liner to make predictions from a set of feature values.  In this case, we'll simply feed the same X values used to train the model, but in live usage, of course, we'd want to apply the trained model to _new_ X values.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        symbol\n",
       "2016-12-22  AAPL     -0.001943\n",
       "            CSCO      0.003121\n",
       "2016-12-23  AAPL     -0.000231\n",
       "            CSCO      0.002466\n",
       "2016-12-27  AAPL      0.002638\n",
       "            CSCO      0.001447\n",
       "2016-12-28  AAPL     -0.002669\n",
       "            CSCO     -0.000287\n",
       "2016-12-29  AAPL      0.000690\n",
       "            CSCO      0.002967\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.predict(X),index=X.index).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me pause here to emphasize the most critical point to understand about this framework.  Read this twice!\n",
    "\n",
    "The date of a feature row represents the day when a value would be known _after that day's trading_, using the feature value date as T=0.  The date of an outcome row represents what will happen in the n days _following_ that date.\n",
    "\n",
    "** Predictions are indexed to the date of the _evening_ when the model could have been run**, _not_ on the day when it could have been traded. \n",
    "\n",
    "In other words, on 2016-12-23, the prediction value represents what the model believes will happen _after_ 12/23.  In practical usage, we can't start using the trading signal until T+1 (since we can't get predictions until after markets are closed on T+0).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary\n",
    "This post presented the concept of organizing data into a `features` dataframe and `outcome` dataframe, and then showed how simple it is to join these two dataframes together to train a model.  \n",
    "\n",
    "True, the convention may take a few examples to get used to.  However, after trial and error, I've found this to be the most error-resistant, flexible, and high-performance way to go.\n",
    "\n",
    "In the [next post], I will share some methods of feature engineering and feature selection.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
